cwlVersion: v1.0

class: CommandLineTool
id: stage-out
doc: "Stage-out the results to S3"

hints:
  "cwltool:Secrets":
    secrets:
    - aws_access_key_id
    - aws_secret_access_key
    - region_name
    - endpoint_url

inputs: 
  s3_bucket:
    type: string
  sub_path:
    type: string
  aws_access_key_id:
    type: string
  aws_secret_access_key:
    type: string
  region_name:
    type: string
  endpoint_url:
    type: string
outputs: 
  s3_catalog_output:
    outputBinding:
      outputEval: ${  return "s3://" + inputs.s3_bucket + "/" + inputs.sub_path + "/catalog.json"; }
    type: string

baseCommand: 
- python
- stage.py

arguments:
  - $( inputs.wf_outputs.path )
  - $( inputs.s3_bucket )
  - $( inputs.sub_path )
  - $( inputs.aws_access_key_id )
  - $( inputs.aws_secret_access_key )
  - $( inputs.region_name )
  - $( inputs.endpoint_url )
  
requirements:
  DockerRequirement:
    dockerPull: stac-asset:latest
  InlineJavascriptRequirement: {}
  EnvVarRequirement:
    envDef:
      A: "2"
  ResourceRequirement: {}
  InitialWorkDirRequirement:
    listing:
    - entryname: stage.py
      entry: |-
        import os
        import sys
        import pystac
        import botocore
        import boto3
        import shutil
        from pystac.stac_io import DefaultStacIO, StacIO
        from urllib.parse import urlparse

        cat_url = sys.argv[1]
        bucket = sys.argv[2]
        subfolder = sys.argv[3]
        aws_access_key_id = sys.argv[4]
        aws_secret_access_key = sys.argv[5]
        region_name = sys.argv[6]
        endpoint_url = sys.argv[7]
        
        shutil.copytree(cat_url, "/tmp/catalog")
        cat = pystac.read_file(os.path.join("/tmp/catalog", "catalog.json"))

        class CustomStacIO(DefaultStacIO):
            """Custom STAC IO class that uses boto3 to read from S3."""

            def __init__(self):
                self.session = botocore.session.Session()
                self.s3_client = self.session.create_client(
                    service_name="s3",
                    use_ssl=True,
                    aws_access_key_id=aws_access_key_id,
                    aws_secret_access_key=aws_secret_access_key,
                    endpoint_url=endpoint_url,
                    region_name=region_name,
                )

            def write_text(self, dest, txt, *args, **kwargs):
                parsed = urlparse(dest)
                if parsed.scheme == "s3":
                    self.s3_client.put_object(
                        Body=txt.encode("UTF-8"),
                        Bucket=parsed.netloc,
                        Key=parsed.path[1:],
                        ContentType="application/geo+json",
                    )
                else:
                    super().write_text(dest, txt, *args, **kwargs)


        client = boto3.client(
            "s3",
            aws_access_key_id=aws_access_key_id,
            aws_secret_access_key=aws_secret_access_key,
            endpoint_url=endpoint_url,
            region_name=region_name,
        )

        StacIO.set_default(CustomStacIO)

        for item in cat.get_items():
            for key, asset in item.get_assets().items():
                s3_path = os.path.normpath(
                    os.path.join(os.path.join(subfolder, item.id, asset.href))
                )
                print(f"upload {asset.href} to s3://{bucket}/{s3_path}",file=sys.stderr)
                client.upload_file(
                    asset.get_absolute_href(),
                    bucket,
                    s3_path,
                )
            # upload item to S3
            print(f"upload {item.id} to s3://{bucket}/{subfolder}", file=sys.stderr)
            pystac.write_file(item, item.get_self_href())

        cat.normalize_hrefs(f"s3://{bucket}/{subfolder}")

        # upload catalog to S3
        print(f"upload catalog.json to s3://{bucket}/{subfolder}", file=sys.stderr)
        pystac.write_file(cat, cat.get_self_href())

        print(f"s3://{bucket}/{subfolder}/catalog.json", file=sys.stdout)
  
